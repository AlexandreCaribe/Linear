{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capítulo 10 Data Science do Zero - Visão Computacional e Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificação de Imagens utitlizando Transfer Learning\n",
    "### Kaggle Dataset Competition: https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![dogs-cat](imagens/dogs-cats.png \"dogs-cats\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### verificando a base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "print(os.listdir(\"datasets\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "print(os.listdir(\"datasets/train\")[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### diretorios de imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'datasets/train'\n",
    "test_dir = 'datasets/test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### listas com as imagens de treino e test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cf9b6bdfbb7bbeff9f5da51eadb71faf8a451603"
   },
   "outputs": [],
   "source": [
    "train_imgs = ['datasets/train/{}'.format(i) for i in os.listdir(train_dir)]\n",
    "test_imgs = ['datasets/test/{}'.format(i) for i in os.listdir(test_dir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Quantidade de imagens de treino:{train} e test:{test}\".format(train=len(train_imgs),test=len(test_imgs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### aleatorizando as imagens de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(train_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_imgs[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### importando as bibliotecas necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "18ea669e7f0ede7c486c1d49b5b6e8256d7a807e"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker\n",
    "import seaborn as sns\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### definindo as dimensões das imagens de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = 150\n",
    "ncolumns = 150\n",
    "channels = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### função para processamento das imagens e classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### efetuando o resize nas imagens e definindo os valores inteiros para as classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5f4f8d5cba1748b3c9a800aef21b3665da8d4615"
   },
   "outputs": [],
   "source": [
    "def read_and_process_image(list_of_images):  \n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for image in list_of_images:\n",
    "        image_ = Image.open(image)\n",
    "        X.append(np.asarray(image_.resize((nrows,ncolumns))))\n",
    "        \n",
    "        if 'dog' in image:\n",
    "            y.append(1)\n",
    "        elif 'cat' in image:\n",
    "            y.append(0)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "00cc550b88aaf9185b76a222b1e71334852c96e4"
   },
   "outputs": [],
   "source": [
    "X, y = read_and_process_image(train_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### transformando a lista de imagens e classes em array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### visualizando algumas imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "66b3ba8fa1cc19c4a074ce8fa3de2861aa15d14e"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "columns = 5\n",
    "for i in range(columns):\n",
    "    plt.subplot(5 / columns + 1, columns, i + 1)\n",
    "    plt.imshow(X[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### separando as imagens os dados em treino e test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1be578474747d0b493dd38b65422e53b524463ef"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.20, random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8776a451cd2055acfa494764934ee6e9dcb49fbe"
   },
   "source": [
    "Now lets create our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### instalando as bibliotecas keras e tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importando o modelo pre-treinado ImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "232be44fb2282fd93a783c999a86145c199963d8"
   },
   "outputs": [],
   "source": [
    "from keras.applications import InceptionResNetV2\n",
    "conv_base = InceptionResNetV2(weights='imagenet', include_top=False, input_shape=(150,150,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Verificando a arquitetura da rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "516f101110b3b7705bde4c4d1fba77af96fd4cd3"
   },
   "outputs": [],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### importando a biblioteca keras para criar a rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### criando o modelo utilizando a rede convolucional como base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "996596d2355a4c1e57f79e477dd6b2f75d868176"
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Verificando novamente a arquitetura da rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3819c1880f1b9b85bebe70d60747fbcacfdd2198"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Verificando o numero de pesos a ajustar sem utilizar a rede pré-treinada e após.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "89c5b84a4485be583f71a809bb936fe71fb6b023"
   },
   "outputs": [],
   "source": [
    "print('Número de pesos ajustáveis sem utilizar a rede convolucional:', len(model.trainable_weights))\n",
    "conv_base.trainable = False\n",
    "print('Número de pesos ajustáveis utilizando a rede convolucional::', len(model.trainable_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Criação dos conjuntos de dados de treino e test utilizando Data Augmentation para prevenir overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e76686be36b4cf570402eb52db63901e4d42df84"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                    rotation_range=40,\n",
    "                                    width_shift_range=0.2,\n",
    "                                    height_shift_range=0.2,\n",
    "                                    shear_range=0.2,\n",
    "                                    zoom_range=0.2,\n",
    "                                    horizontal_flip=True,\n",
    "                                    fill_mode='nearest')\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "ntrain = len(X_train)\n",
    "nval = len(X_val)\n",
    "batch_size = 32\n",
    "\n",
    "train_generator = train_datagen.flow(X_train, y_train,batch_size=batch_size)\n",
    "val_generator = val_datagen.flow(X_val, y_val, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Criando um modelo binário para treinar as nossas imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "576d8d10a4b6f59fa39e9bc44b954aae887d2954",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizers.RMSprop(lr=2e-5), metrics=['acc'])\n",
    "\n",
    "history = model.fit_generator(train_generator,\n",
    "                              steps_per_epoch=ntrain // batch_size,\n",
    "                              epochs=20,\n",
    "                              validation_data=val_generator,\n",
    "                              validation_steps=nval // batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Salvando o modelo e pesos em disco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "770dacdaf6156a5d45737faafc7b9b03c34d2b66"
   },
   "outputs": [],
   "source": [
    "model.save_weights('model_wieghts.h5')\n",
    "model.save('model_keras.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Salvando o arquivo de historico em disco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('history.pckl', 'wb')\n",
    "pickle.dump(history.history, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Carregando o modelo a partir do disco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"model_keras.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Carregando o arquivo de historico a partir do disco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('history.pckl', 'rb')\n",
    "historico = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualizando as métricas do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = historico['acc']\n",
    "val_acc = historico['val_acc']\n",
    "loss = historico['loss']\n",
    "val_loss = historico['val_loss']\n",
    "epochs = range(1, len(acc) + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Acurácia de treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs, acc, 'b', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation accuracy')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Função de perda de treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "02e8aaf73583b328f76b025240eb9914cdf12bf0"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Função para suavizar os dados e melhorar a visualização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5c3c9ad9891dae2d5a3f24c460a1c3e322dc6089"
   },
   "outputs": [],
   "source": [
    "def smooth_plot(points, factor=0.7):\n",
    "    smooth_pts = []\n",
    "    for point in points:\n",
    "        if smooth_pts:\n",
    "            previous = smooth_pts[-1]\n",
    "            smooth_pts.append(previous * factor + point * (1 - factor))\n",
    "        else:\n",
    "            smooth_pts.append(point)\n",
    "    return smooth_pts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Acurácia de treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "badb83ae16e7e826575fedcaf0b684d099aebc7e"
   },
   "outputs": [],
   "source": [
    "plt.plot(epochs, smooth_plot(acc), 'b', label='Training accurarcy')\n",
    "plt.plot(epochs, smooth_plot(val_acc), 'r', label='Validation accurarcy')\n",
    "plt.title('Training and Validation accurarcy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testando os resultados de predição"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Selecionando 10 imagens a partir do conjunto de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = read_and_process_image(test_imgs[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### transformando a lista de imagens em array e aplicando a rescala dos pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4a3e841ea9e128d78d441116a446d2dcfe87b088"
   },
   "outputs": [],
   "source": [
    "x = np.array(X_test)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### plotando as imagens e suas respectivas classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3cb40f6f11ea6124330eb9c41774fc74ad3c266d"
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "columns = 5\n",
    "text_labels = []\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "for batch in test_datagen.flow(x, batch_size=1):\n",
    "    pred = model.predict_classes(batch)\n",
    "    if pred == 1:\n",
    "        text_labels.append('dog')\n",
    "    else:\n",
    "        text_labels.append('cat')\n",
    "    \n",
    "    plt.subplot(5 / columns + 1, columns, i + 1)\n",
    "    plt.title('Classe: ' + text_labels[i])\n",
    "    \n",
    "    imgplot = plt.imshow(batch[0])\n",
    "    i += 1\n",
    "    if i % 10 == 0:\n",
    "        break\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
